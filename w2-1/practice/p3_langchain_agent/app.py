import streamlit as st
import time
from langchain_core.messages import HumanMessage, AIMessage
from utils import load_model, set_memory, create_vectordb, create_agent, invoke_agent

st.title("ğŸ“Šê¸ˆìœµ ìƒë‹´ ì—ì´ì „íŠ¸")
st.markdown("<br>", unsafe_allow_html=True)

model_name = st.selectbox("**ëª¨ë¸ì„ ê³¨ë¼ì£¼ì„¸ìš”.**", 
                          ("gpt-4o", "gpt-4-turbo", "gpt-4", "gpt-3.5-turbo"), 
                          index=0, 
                          key="model_name_select")

st.session_state.model_name = model_name

if "chat_started" not in st.session_state:
    st.session_state.chat_started = False
    st.session_state.memory = None
    st.session_state.vectordb = None 
    st.session_state.agent = None
    st.session_state.uploaded_files = None

def start_chat(uploaded_files):
    llm = load_model(st.session_state.model_name)
    st.session_state.chat_started = True
    st.session_state.memory = set_memory()
    if uploaded_files:
        st.session_state.vectordb = create_vectordb(uploaded_files)
    else:
        st.session_state.vectordb = None 
    st.session_state.agent = create_agent(llm, st.session_state.vectordb, st.session_state.memory)

def config_change(uploaded_files):
    llm = load_model(st.session_state.model_name)
    st.session_state.vectordb = create_vectordb(uploaded_files)
    st.session_state.agent = create_agent(llm, st.session_state.vectordb, st.session_state.memory)

with st.sidebar:
    st.header("ë¶„ì„í•  ê¸°ì—…ì˜ ì—°ê°„ ë³´ê³ ì„œ/ë¶„ê¸° ë³´ê³ ì„œë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    uploaded_files = st.file_uploader("Upload your documents", accept_multiple_files=True, type=["pdf"])

    if uploaded_files:
        st.session_state.uploaded_files = uploaded_files
        with st.spinner('ì ì‹œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš” ...ğŸ§šâ€â™€ï¸'):
            config_change(uploaded_files)

if st.button("Start Chat"):
    with st.spinner('ì ì‹œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš” ...ğŸ§šâ€â™€ï¸'):
        start_chat(st.session_state.uploaded_files)

st.markdown("<br>", unsafe_allow_html=True)

if st.session_state.chat_started:
    if st.session_state.memory is None or st.session_state.agent is None:
        start_chat(st.session_state.uploaded_files)

    for message in st.session_state.memory.chat_memory.messages:
        if isinstance(message, HumanMessage):
            role = "user"
        elif isinstance(message, AIMessage):
            role = "assistant"
        else:
            continue
        with st.chat_message(role):
            st.markdown(message.content)

    if prompt := st.chat_input():
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            response_content = invoke_agent(st.session_state.agent, prompt)
            response_content = response_content.replace('$', '\\$')

            for line in response_content.split('\n'):
                for chunk in line.split():
                    full_response += chunk + " "
                    time.sleep(0.05)
                    message_placeholder.markdown(full_response + "â–Œ")
                full_response += '\n'

            message_placeholder.markdown(full_response.strip())

